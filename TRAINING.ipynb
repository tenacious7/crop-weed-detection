{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ceb8e-31af-446a-80c7-8865c1f50002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "SYNTHETIC_DATA_DIR = r\"C:\\IMMAGE ANALYSIS PROJECT DATASET\\weed\\weeds\\output\\images\"\n",
    "MASK_DIR = r\"C:\\IMMAGE ANALYSIS PROJECT DATASET\\weed\\weeds\\output\\masks\"\n",
    "VISUALIZATION_DIR = r\"C:\\IMMAGE ANALYSIS PROJECT DATASET\\weed\\weeds\\output\\visualization\"\n",
    "\n",
    "\n",
    "class LightweightUNet(nn.Module):\n",
    "    def __init__(self, n_classes=3):\n",
    "        super(LightweightUNet, self).__init__()\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        self.enc1 = self._conv_block(3, 32)\n",
    "        self.enc2 = self._conv_block(32, 64)\n",
    "        self.enc3 = self._conv_block(64, 128)\n",
    "        self.enc4 = self._conv_block(128, 256)\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = self._conv_block(256, 128)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = self._conv_block(128, 64)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = self._conv_block(64, 32)\n",
    "        \n",
    "        self.final = nn.Conv2d(32, n_classes, kernel_size=1)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def _conv_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.max_pool(e1)\n",
    "        \n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.max_pool(e2)\n",
    "        \n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.max_pool(e3)\n",
    "        \n",
    "        # Bridge\n",
    "        e4 = self.enc4(p3)\n",
    "        \n",
    "        # Decoder path\n",
    "        d3 = self.up3(e4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        return self.final(d1)\n",
    "\n",
    "class PlantSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = [img for img in sorted(os.listdir(image_dir)) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, img_name.replace('synthetic', 'mask'))\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Image not found or unable to read at {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Load mask\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise ValueError(f\"Mask not found or unable to read at {mask_path}\")\n",
    "            \n",
    "            # One-hot encode mask\n",
    "            mask_one_hot = np.zeros((3, mask.shape[0], mask.shape[1]), dtype=np.float32)\n",
    "            for i in range(3):\n",
    "                mask_one_hot[i, :, :] = (mask == i).astype(np.float32)\n",
    "\n",
    "            # Apply transformations\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, mask=mask_one_hot.transpose(1, 2, 0))\n",
    "                image = augmented['image']\n",
    "                mask_one_hot = augmented['mask'].permute(2, 0, 1)  # Change from HWC to CHW format\n",
    "\n",
    "            return image, mask_one_hot\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {img_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "def get_transforms(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.GaussNoise(p=0.2),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "def plot_training_history(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with tqdm(dataloader, desc='Training') as pbar:\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def main():\n",
    "    # Set up paths and parameters\n",
    "    BATCH_SIZE = 4  # Reduced batch size\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Datasets and loaders\n",
    "    train_dataset = PlantSegmentationDataset(\n",
    "        SYNTHETIC_DATA_DIR,\n",
    "        MASK_DIR,\n",
    "        transform=get_transforms(train=True)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # No multiprocessing\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model, criterion, optimizer\n",
    "    model = LightweightUNet().to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Plot and save training history\n",
    "    plot_training_history(train_losses, [])\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6f602f-c3ee-4910-abbe-c142080305d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (iou_total \u001b[38;5;241m/\u001b[39m num_batches, dice_total \u001b[38;5;241m/\u001b[39m num_batches,\n\u001b[0;32m     46\u001b[0m             precision_total \u001b[38;5;241m/\u001b[39m num_batches, recall_total \u001b[38;5;241m/\u001b[39m num_batches)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Load test dataset\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m test_transform \u001b[38;5;241m=\u001b[39m get_transforms(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     50\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m PlantSegmentationDataset(test_image_dir, test_mask_dir, transform\u001b[38;5;241m=\u001b[39mtest_transform)\n\u001b[0;32m     51\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_transforms' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the paths and device\n",
    "model_dir = \"saved_models\"\n",
    "test_image_dir = \"path_to_test_images\"\n",
    "test_mask_dir = \"path_to_test_masks\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the metric calculations\n",
    "def calculate_metrics(pred, target):\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    target = target.detach().cpu().numpy()\n",
    "    \n",
    "    # Threshold the predictions\n",
    "    pred = (pred > 0.5).astype(np.uint8)\n",
    "    \n",
    "    iou = jaccard_score(target.flatten(), pred.flatten(), average='macro')\n",
    "    dice = f1_score(target.flatten(), pred.flatten(), average='macro')\n",
    "    precision = precision_score(target.flatten(), pred.flatten(), average='macro')\n",
    "    recall = recall_score(target.flatten(), pred.flatten(), average='macro')\n",
    "    \n",
    "    return iou, dice, precision, recall\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    iou_total, dice_total, precision_total, recall_total = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            iou, dice, precision, recall = calculate_metrics(outputs, masks)\n",
    "            \n",
    "            iou_total += iou\n",
    "            dice_total += dice\n",
    "            precision_total += precision\n",
    "            recall_total += recall\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    return (iou_total / num_batches, dice_total / num_batches,\n",
    "            precision_total / num_batches, recall_total / num_batches)\n",
    "\n",
    "# Load test dataset\n",
    "test_transform = get_transforms(train=False)\n",
    "test_dataset = PlantSegmentationDataset(test_image_dir, test_mask_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Loop through all saved models and evaluate\n",
    "results = {}\n",
    "for model_file in sorted(os.listdir(model_dir)):\n",
    "    if model_file.endswith('.pt'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        print(f\"Evaluating {model_file}...\")\n",
    "        \n",
    "        # Load model\n",
    "        model = LightweightUNet().to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        iou, dice, precision, recall = evaluate_model(model, test_loader)\n",
    "        results[model_file] = {\"IoU\": iou, \"Dice\": dice, \"Precision\": precision, \"Recall\": recall}\n",
    "\n",
    "# Print the results for storytelling\n",
    "print(\"Evaluation results for each model checkpoint:\")\n",
    "for model_file, metrics in results.items():\n",
    "    print(f\"{model_file} - IoU: {metrics['IoU']:.4f}, Dice: {metrics['Dice']:.4f}, Precision: {metrics['Precision']:.4f}, Recall: {metrics['Recall']:.4f}\")\n",
    "\n",
    "# Insights: Identify the highest scoring models to help decide on which checkpoint(s) perform best.\n",
    "best_model = max(results, key=lambda x: results[x]['IoU'])\n",
    "print(f\"\\nBest model based on IoU: {best_model} with IoU: {results[best_model]['IoU']:.4f}\")\n",
    "\n",
    "# Optionally, save the results to a file for further analysis.\n",
    "import json\n",
    "with open(\"model_performance_summary.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9682f42-5ecb-44b2-b499-9a62fdc5c07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
