# ğŸŒ¾ AI-Powered Weed Detection in Tomato Fields using Deep Learning

![Python](https://img.shields.io/badge/Python-3.10-blue)
![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer_Vision-green)
![Status](https://img.shields.io/badge/Status-Active-success)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## ğŸ§  Project Overview

This project implements an **AI-driven weed detection system** for tomato fields using **Deep Learning** and **Computer Vision**.
The model performs **semantic segmentation** to classify each pixel of an image into **tomato crop**, **weed**, or **background**, allowing precise weed localization and removal.

> ğŸ’¡ Goal: Automate weed detection to reduce manual labor and improve crop yield in tomato farming.

---

## ğŸ¯ Project Objectives

- Build a **synthetic dataset pipeline** combining background field images with weed and tomato samples.
- Train a **lightweight U-Net model** optimized for speed and accuracy.
- Enable **real-time inference** for weed detection and localization.
- Provide **visual overlays** and **bounding boxes** for interpretability.

---

## ğŸ§© Methodology

### 1ï¸âƒ£ Data Collection & Synthesis

Synthetic data is generated by blending transparent foreground plant images with real agricultural field backgrounds.

- **Data Sources:**
  - Background: Real agricultural field images
  - Foreground: Tomato crop and weed images
- **Augmentation:** Random scaling, rotation, brightness/contrast, and Gaussian noise
- **Output Classes:**
  - `0` - Background (Black)
  - `1` - Tomato Crop (Green)
  - `2` - Weed (Red)
- **Dataset Size:** 1000+ synthetic samples with segmentation masks

---

### 2ï¸âƒ£ Model Architecture

A lightweight **U-Net** designed for efficient semantic segmentation.

| Component | Details |
|------------|----------|
| **Encoder** | 4 convolutional blocks (32 â†’ 64 â†’ 128 â†’ 256 channels) |
| **Decoder** | Transposed convolutions with skip connections |
| **Output** | 3-channel segmentation mask (tomato, weed, background) |
| **Total Parameters** | ~1.9 Million (fast + lightweight) |
| **Framework** | PyTorch |

---

### 3ï¸âƒ£ Training Pipeline

| Parameter | Value |
|------------|--------|
| **Loss Function** | Binary Cross-Entropy with Logits |
| **Optimizer** | Adam (lr = 0.001) |
| **Batch Size** | 4 |
| **Epochs** | 50 |
| **Augmentations** | Random rotations, flips, contrast, and Gaussian noise |
| **Hardware** | GPU-accelerated (if available) |

---

### 4ï¸âƒ£ Inference and Visualization

- **Preprocessing:** Image resizing with aspect ratio preservation â†’ 480Ã—480
- **Post-processing:** Connected component analysis for weed & tomato bounding boxes
- **Output:**
  - Segmented mask
  - Tomato & weed count
  - Bounding box overlay

---

## ğŸ“Š Results

The model successfully:
- Distinguishes **tomato vs weed** regions accurately
- Generates **clear masks & bounding boxes**
- Runs **in real-time** on mid-range GPUs
- Provides **interpretable visual outputs**

---

## ğŸ“ Project Structure

```
Weed-Detection/
â”‚
â”œâ”€â”€ DATA COLLECTION .ipynb      # Synthetic dataset generation
â”œâ”€â”€ TRAINING.ipynb              # Model training pipeline
â”œâ”€â”€ IMPLIMENTATION.ipynb        # Inference and visualization
â”œâ”€â”€ ALL.ipynb                   # Combined notebook (if used)
â”œâ”€â”€ TRANING.ipynb               # Alternative training notebook
â”œâ”€â”€ training_history.png        # Training loss graph
â”œâ”€â”€ saved_models/               # Model checkpoints
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .gitignore                  # Git ignore file
â””â”€â”€ README.md                   # This file
```

---

## ğŸ§° Tech Stack

| Category | Tools |
|----------|--------|
| Language | Python |
| Deep Learning | PyTorch, Torchvision |
| Computer Vision | OpenCV, Albumentations |
| Visualization | Matplotlib |
| Data Handling | NumPy |

---

## ğŸ§¾ Installation

1. Clone the repository:
   ```bash
   git clone <your-repo-url>
   cd <project-directory>
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸš€ Usage

### Data Generation
Run `DATA COLLECTION .ipynb` to generate synthetic dataset.

### Training
Run `TRAINING.ipynb` to train the U-Net model.

### Inference
Run `IMPLIMENTATION.ipynb` to perform weed detection on new images.

---

## ğŸ“ˆ Input Dataset Details

- **Background Images:** Real agricultural field photos (256x256)
- **Weed Images:** Transparent PNG images of various weeds
- **Tomato Images:** Tomato plant images with alpha channel
- **Synthetic Generation:** 1000 images created by overlaying weeds and tomatoes on backgrounds
- **Masks:** 3-class segmentation masks (background, tomato, weed)

---

## ğŸ“Š Output Details

- **Segmentation Masks:** Pixel-wise classification into 3 classes
- **Bounding Boxes:** Rectangular boxes around detected weeds and tomatoes
- **Visualization:** Colored overlays showing detected regions
- **Statistics:** Count of weeds and tomato plants in the image
- **Saved Results:** Images with segmentation and bounding boxes

---

## ğŸ§  Future Enhancements

- ğŸ”¹ Train with real-world agricultural datasets
- ğŸ”¹ Optimize for edge devices
- ğŸ”¹ Add multi-temporal monitoring
- ğŸ”¹ Integrate with robotic weed removal systems

---

## ğŸ‘¨â€ğŸ’» Author

Brijesh Kumar Ghadei
ğŸŒ± Computer Science Student | AI & Innovation Enthusiast
ğŸ“ India

---

## ğŸ“œ License

This project is licensed under the MIT License.
